{"cells":[{"cell_type":"code","source":["import keras\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["# Setting seed for reproducability\nnp.random.seed(1234)  \nPYTHONHASHSEED = 0\nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix, recall_score, precision_score\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM, Activation\n#%matplotlib inline"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# read training data \ntrain_df = pd.read_csv('http://azuremlsamples.azureml.net/templatedata/PM_train.txt', sep=\" \", header=None)\ntrain_df.drop(train_df.columns[[26, 27]], axis=1, inplace=True)\ntrain_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n                     's15', 's16', 's17', 's18', 's19', 's20', 's21']\n\n# read test data\ntest_df = pd.read_csv('http://azuremlsamples.azureml.net/templatedata/PM_test.txt', sep=\" \", header=None)\ntest_df.drop(test_df.columns[[26, 27]], axis=1, inplace=True)\ntest_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n                     's15', 's16', 's17', 's18', 's19', 's20', 's21']\n\n# read ground truth data\ntruth_df = pd.read_csv('http://azuremlsamples.azureml.net/templatedata/PM_truth.txt', sep=\" \", header=None)\ntruth_df.drop(truth_df.columns[[1]], axis=1, inplace=True)\n\ntruth_df.shape\n\ntrain_df = train_df.sort_values(['id','cycle'])\ntrain_df.head()"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# Data Labeling - generate column RUL\nrul = pd.DataFrame(train_df.groupby('id')['cycle'].max()).reset_index()\nrul.columns = ['id', 'max']\ntrain_df = train_df.merge(rul, on=['id'], how='left')\ntrain_df['RUL'] = train_df['max'] - train_df['cycle']\ntrain_df.drop('max', axis=1, inplace=True)\ntrain_df.head()"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# generate label columns for training data\nw1 = 30\nw0 = 15\ntrain_df['label1'] = np.where(train_df['RUL'] <= w1, 1, 0 )\ntrain_df['label2'] = train_df['label1']\ntrain_df.loc[train_df['RUL'] <= w0, 'label2'] = 2\ntrain_df.head()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# MinMax normalization\ntrain_df['cycle_norm'] = train_df['cycle']\ncols_normalize = train_df.columns.difference(['id','cycle','RUL','label1','label2'])\nmin_max_scaler = preprocessing.MinMaxScaler()\nnorm_train_df = pd.DataFrame(min_max_scaler.fit_transform(train_df[cols_normalize]), \n                             columns=cols_normalize, \n                             index=train_df.index)\njoin_df = train_df[train_df.columns.difference(cols_normalize)].join(norm_train_df)\ntrain_df = join_df.reindex(columns = train_df.columns)\ntrain_df.head()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# Next, we prepare the test data\ntest_df['cycle_norm'] = test_df['cycle']\nnorm_test_df = pd.DataFrame(min_max_scaler.transform(test_df[cols_normalize]), \n                            columns=cols_normalize, \n                            index=test_df.index)\ntest_join_df = test_df[test_df.columns.difference(cols_normalize)].join(norm_test_df)\ntest_df = test_join_df.reindex(columns = test_df.columns)\ntest_df = test_df.reset_index(drop=True)\ntest_df.head()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["# generate column max for test data\nrul = pd.DataFrame(test_df.groupby('id')['cycle'].max()).reset_index()\nrul.columns = ['id', 'max']\ntruth_df.columns = ['more']\ntruth_df['id'] = truth_df.index + 1\ntruth_df['max'] = rul['max'] + truth_df['more']\ntruth_df.drop('more', axis=1, inplace=True)\n\n# generate RUL for test data\ntest_df = test_df.merge(truth_df, on=['id'], how='left')\ntest_df['RUL'] = test_df['max'] - test_df['cycle']\ntest_df.drop('max', axis=1, inplace=True)\ntest_df.head()"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["# generate label columns w0 and w1 for test data\ntest_df['label1'] = np.where(test_df['RUL'] <= w1, 1, 0 )\ntest_df['label2'] = test_df['label1']\ntest_df.loc[test_df['RUL'] <= w0, 'label2'] = 2\ntest_df.head()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["# MODELLING.....pick a large window size of 50 cycles\nsequence_length = 50\n\n# preparing data for visualizations \n# window of 50 cycles prior to a failure point for engine id 3\nengine_id3 = test_df[test_df['id'] == 3]\nengine_id3_50cycleWindow = engine_id3[engine_id3['RUL'] <= engine_id3['RUL'].min() + 50]\ncols1 = ['s1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10']\nengine_id3_50cycleWindow1 = engine_id3_50cycleWindow[cols1]\ncols2 = ['s11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21']\nengine_id3_50cycleWindow2 = engine_id3_50cycleWindow[cols2]\n\n# plotting sensor data for engine ID 3 prior to a failure point - sensors 1-10 . For now Databricks did not support pandas.plot()\n# engine_id3_50cycleWindow1.plot(subplots=True, sharex=True, figsize=(20,20))\n\n# plotting sensor data for engine ID 3 prior to a failure point - sensors 11-21 \n# engine_id3_50cycleWindow2.plot(subplots=True, sharex=True, figsize=(20,20))\n"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["# function to reshape features into (samples, time steps, features) \ndef gen_sequence(id_df, seq_length, seq_cols):\n    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n    we can use shorter ones \"\"\"\n    data_array = id_df[seq_cols].values\n    num_elements = data_array.shape[0]\n    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n        yield data_array[start:stop, :]\n        \n# pick the feature columns \nsensor_cols = ['s' + str(i) for i in range(1,22)]\nsequence_cols = ['setting1', 'setting2', 'setting3', 'cycle_norm']\nsequence_cols.extend(sensor_cols)\n\n# generator for the sequences\nseq_gen = (list(gen_sequence(train_df[train_df['id']==id], sequence_length, sequence_cols)) \n           for id in train_df['id'].unique())\n\n# generate sequences and convert to numpy array\nseq_array = np.concatenate(list(seq_gen)).astype(np.float32)\nseq_array.shape\n\n\n# function to generate labels\ndef gen_labels(id_df, seq_length, label):\n    data_array = id_df[label].values\n    num_elements = data_array.shape[0]\n    return data_array[seq_length:num_elements, :]\n\n# generate labels\nlabel_gen = [gen_labels(train_df[train_df['id']==id], sequence_length, ['label1']) \n             for id in train_df['id'].unique()]\nlabel_array = np.concatenate(label_gen).astype(np.float32)\nlabel_array.shape"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# Define the LSTM network\nnb_features = seq_array.shape[2]\nnb_out = label_array.shape[1]\n\nmodel = Sequential()\n\nmodel.add(LSTM(\n         input_shape=(sequence_length, nb_features),\n         units=100,\n         return_sequences=True))\nmodel.add(Dropout(0.2))\n\nmodel.add(LSTM(\n          units=50,\n          return_sequences=False))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(units=nb_out, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nprint(model.summary())"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["#%%time\n# Train the network\nmodel.fit(seq_array, label_array, epochs=10, batch_size=200, validation_split=0.05, verbose=1,\n          callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')])\n\n# training metrics\nscores = model.evaluate(seq_array, label_array, verbose=1, batch_size=200)\nprint('Accurracy: {}'.format(scores[1]))\n"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["# make predictions and compute confusion matrix\ny_pred = model.predict_classes(seq_array,verbose=1, batch_size=200)\ny_true = label_array\nprint('Confusion matrix\\n- x-axis is true labels.\\n- y-axis is predicted labels')\ncm = confusion_matrix(y_true, y_pred)\ncm"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["\n# compute precision and recall\nprecision = precision_score(y_true, y_pred)\nrecall = recall_score(y_true, y_pred)\nprint( 'precision = ', precision, '\\n', 'recall = ', recall)\n\n# compute AUC\nfrom sklearn.metrics import roc_auc_score\nauc = roc_auc_score(y_true, y_pred)\nprint( 'auc = ', auc)\n"],"metadata":{},"outputs":[],"execution_count":15}],"metadata":{"name":"LSTM_TEST","notebookId":4079480555915579},"nbformat":4,"nbformat_minor":0}
